# -*- coding: utf-8 -*-
"""K means.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16yGbtBW-0Io9ZCULpzkmcVKKfvPdd2gG
"""

import pandas as pd
import numpy as np

# Seed for reproducibility
np.random.seed(42)

# Cluster 1: Low CGPA & IQ
cgpa1 = np.random.normal(2.3, 0.15, 30)   # around 2.3
iq1   = np.random.normal(88, 4, 30)       # around 88

# Cluster 2: Medium CGPA & IQ
cgpa2 = np.random.normal(3.2, 0.15, 35)   # around 3.2
iq2   = np.random.normal(105, 5, 35)      # around 105

# Cluster 3: High CGPA & IQ
cgpa3 = np.random.normal(3.8, 0.1, 35)    # around 3.8
iq3   = np.random.normal(118, 3, 35)      # around 118

# Combine all clusters
CGPA = np.concatenate([cgpa1, cgpa2, cgpa3])
IQ   = np.concatenate([iq1, iq2, iq3])
students = [f"S{i}" for i in range(1, len(CGPA)+1)]

# Create DataFrame
df = pd.DataFrame({"Student": students, "CGPA": CGPA, "IQ": IQ})
print(df.head(10))

import matplotlib.pyplot as plt
import seaborn as sns
plt.scatter(df['CGPA'], df['IQ'])
plt.xlabel('CGPA')
plt.ylabel('IQ')
plt.title('CGPA vs IQ')
plt.show()

## checking the clusters
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

wcss=[]
for i in range(1,11):
    kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)
    kmeans.fit(df[['CGPA','IQ']])
    wcss.append(kmeans.inertia_)

wcss

## plotting it
plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

x=df[['CGPA','IQ']].values
kmeans=KMeans(n_clusters=3,init='k-means++',random_state=42)
kmeans.fit_predict(x)

plt.scatter(x[kmeans.labels_==0,0],x[kmeans.labels_==0,1],s=100,c='blue',label='Cluster 1')
plt.scatter(x[kmeans.labels_==1,0],x[kmeans.labels_==1,1],s=100,c='red',label='Cluster 1')
plt.scatter(x[kmeans.labels_==2,0],x[kmeans.labels_==2,1],s=100,c='green',label='Cluster 1')